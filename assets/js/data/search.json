[ { "title": "Go Schedular", "url": "/posts/Go-Schedular/", "categories": "", "tags": "", "date": "2022-08-24 00:00:00 +0530", "snippet": "Process Process contains common resources that may be allocatedby any process. These resources include but are not limited to a memory addressspace, handles to files, devices, and threads. Process will have various attributes like Process ID Process State Process Priority Program Counter General purpose register List of open files List of open devices Protection information List of child process Pending alarms Signals and signal handlers Accounting information Thread Thread is a light weight process and an thread will share resources of the process like code, data, global variables, files and memory address space among all the thread within the process but stack and register cannot be shared, every thread have it’s own stakcs and registers. Advantages of threads Enhanced throughput of system Imporve responsiveness Faster context switching due to less attributes Effetive utilisation of multiprocessor system Resource sharing (Code, Data, Address Space, Files, Global Variables) User level thread also known as green thread, coroutine in C, goroutine in Go and fiber in Ruby. Process Thread (Kernel Thread) Goroutine / (User Thread) Program under execution is known as a process. it should reside in the main memory and occupies cpu to execute instructions and should be in active state. Kernel level thread is a light weight process and implemented by the Operating system User level thread also light weighted process but implemented by the user/programmer/programming language Context switching time between processes is more and creating a process will take more time. Context switching time between kernel level thread will take less time than context switching between process also creation of kernel level thread also take less time than creation of a process. User level thread is having less context switching time and creation of user level thread will take less time than kernel level thread. OS schedular is responsible for scheduling process The kernel thread scheduler is in charge of scheduling kernel threads. User/Programming Schedular (Golang schedular) is responsible for shceduling user thread/goroutines. So it’s more efficient to create multiple user thread(goroutine ) inside one process as compare to the process creation which is time consuming and resource intensive.Go Specific In Go user level thread is known as Goroutine. Go has took some decision when creating goroutines Easy to create Lightweight Parallel execution Scalable Infinite Stack (Max stack size is 1 GB on 64-bit, 250 MB on 32-bit.) Handling of blocking calls Sending and Receing on Channel Network IO calls Blocking System calls/ syscalls Timers Mutexes Efficient (work stealing) Why Go have a schedular ?Go uses user level thread known as goroutine , which are lighter and cheaper than kernel level thread. for example creation of initial goroutine will take 2KB of stack size and kernel level thread will take 8KB of stack size. Also goroutine has faster creation, destruction and faster context switches than kernel thread So go schedular needs to exits to schedule goroutine.OS can’t schedule user level thread, OS only know about kernel level thread. Go schedular multiplexes goroutines to kernel level threads, which will run on the differnet CPU core. When to schedule goroutines ?If there is any operation that should or would affect goroutine execution like goroutine starting and blocking call etc… How go schedular will multiplexes goroutines into kernel threads ? 1:1 Scheduling (Thread per goroutine) Parallel execution (each thread can run on different core) would work but too expensive. memory at least ~32k (memory for user stack and kernel stacks) performance issues (calling syscall) no infinite stack N:1 Scheduling (Multilex all goroutine on a single kernel thread) no parallelism (can only use a single CPU core, even if more cpu core are available) package main import ( \"fmt\" \"runtime\" \"sync\" ) func main(){ // Allocate 1 logical processor for the scheduler to use. runtime.GOMAXPROCS(1) var wg sync.WaitGroup wg.Add(2) fmt.Println(\"Starting Goroutines\") // Declare an anonymous function and create a goroutine. go func(){ // Schedule the call to Done to tell main we are done. defer wg.Done() // Display the alphabet 3 times for count:=0;count&lt;3;count++{ for ch:='a';ch &lt;'a'+26;ch++{ fmt.Printf(\"%c \",ch) } fmt.Println() } }() // Declare an anonymous function and create a goroutine. go func(){ // Schedule the call to Done to tell main we are done. defer wg.Done() // Display the numbers 3 times for count:=0;count&lt;3;count++{ for n:=1;n &lt;=26;n++{ fmt.Printf(\"%d \",n) } fmt.Println() } }() // Wait for the goroutines to finish. fmt.Println(\"Waiting To Finish\") wg.Wait() fmt.Println(\"\\nTerminating Program\") } &gt; go run main.go Starting Goroutines Waiting To Finish 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z Terminating Program At line 18 and 31 both functions are created as goroutines by the keyword go. You can see by the output that the code inside each goroutine is running concurrently within a single logical processor. Well you can question by seeing the output of this program they are running one after another, so then how it’s running in concurrent mannar. If we set rumtime.GOMAXPROCS() value to 1 than does my program run concurrently ? Let’s consider the same program with time.Sleep func inside the goroutine, which will force go schedular to shcedular another goroutine when first one is blocked. package main import ( \"fmt\" \"runtime\" \"sync\" \"time\" ) func main(){ // Allocate 1 logical processor for the scheduler to use. runtime.GOMAXPROCS(1) var wg sync.WaitGroup wg.Add(2) fmt.Println(\"Starting Goroutines\") // Declare an anonymous function and create a goroutine. go func(){ // Schedule the call to Done to tell main we are done. defer wg.Done() // Display the alphabet 3 times for count:=0;count&lt;3;count++{ if count==1{ time.Sleep(10*time.Second) } for ch:='a';ch &lt;'a'+26;ch++{ fmt.Printf(\"%c \",ch) } fmt.Println() } }() // Declare an anonymous function and create a goroutine. go func(){ // Schedule the call to Done to tell main we are done. defer wg.Done() // Display the numbers 3 times for count:=0;count&lt;3;count++{ if count==0{ time.Sleep(5*time.Second) } if count==2{ time.Sleep(7*time.Second) } for n:=1;n &lt;=26;n++{ fmt.Printf(\"%d \",n) } fmt.Println() } }() // Wait for the goroutines to finish. fmt.Println(\"Waiting To Finish\") wg.Wait() fmt.Println(\"\\nTerminating Program\") } &gt; go run main2.go Starting Goroutines Waiting To Finish a b c d e f g h i j k l m n o p q r s t u v w x y z 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Terminating Program Here you can see even if we set runtime.GOMAXPROCS(1) to 1, the program is running concurrently. Number of Goroutine in Running sate can be max at 1, Block Goroutine can be more than one and all other Goroutine are in Runnable state. Thread Pool Create thread when needed which means create a thread if there are goroutine to run but all the other threads are busy. Once the thread complete it’s execution rather than distroying reuse it. this can only faster goroutine creation because we can reuse threads but still more memory consumption, performance issue and no infinite stacks. M:N Threading Shared Run Queue Schedular M represents number of OS Thread N represents number of goroutine Creation of goroutine is cheap and we can fully control complete lifecycle of goroutine beacuse it’s created in user space. Creation of OS thread is expensive and we don’t have control over it but using multiple thread we can achieve parallelism. In this model multiple goroutine is multiplex into kernel threads. Goroutine state Running Runnable Blocked Blocked on the Channel Mutexes Network IO Timers System Call Blocked Goroutine example package main import ( \"time\" \"fmt\" \"sync\" \"os\" \"net/http\" \"io/ioutil\" ) // Global worker variable var worker int func writeToFile(wg *sync.WaitGroup,){ defer wg.Done() file, _ := os.OpenFile(\"file.txt\", os.O_RDWR|os.O_CREATE, 0755) // Blocking System Call resp, _ := http.Get(\"https://mukeshpilaniya.github.io/posts/Go-Schedular/\") // Blocking Network IO Call body, _ := ioutil.ReadAll(resp.Body) // Blocking System Call file.WriteString(string(body)) } func workerCount(wg *sync.WaitGroup, m *sync.Mutex, ch chan string) { // Lock() the mutex to ensure // exclusive access to the state, // increment the value, // Unlock() the mutex m.Lock() // Blocked On Mutex worker = worker + 1 ch &lt;- fmt.Sprintf(\"Worker %d is ready\",worker) m.Unlock() // On return, notify the // WaitGroup that we’re done. wg.Done() } func printWorker(wg *sync.WaitGroup, done chan bool, ch chan string){ for i:=0;i&lt;100;i++{ fmt.Println(&lt;-ch) // Blocked On Channel } wg.Done() done &lt;-true } func main() { // Creating Channel ch :=make(chan string) done :=make(chan bool) // This mutex will synchronize access to state var mu sync.Mutex // This WaitGroup is used to wait for // all the goroutines launched here to finish. var wg sync.WaitGroup for i:=1;i&lt;=100;i++{ wg.Add(1) go workerCount(&amp;wg,&amp;mu,ch) } wg.Add(2) go writeToFile(&amp;wg) go printWorker(&amp;wg,done,ch) // Waiting for program to Finish wg.Wait() &lt;-done // Blocked On Channel &lt;-time.After(1*time.Second) //Blocked On Timer close(ch) close(done) } In line number 18 and 20 Goroutine is blocked on System call, in line 19 blocked on network IO call, in line 30 blocked on mutex, in line 43 and 74 blocked on channel and in line 76 it’s blocked on timer. Now we will look how goschedular will work in these cases. If a goroutine is blocked on the channel then the channel is having wait Queue(line 10) and all blocked goroutine is listed on the wait queue and it’s easly trackable. After the blocking call they will be placed into global run queue of schedular and OS Thread will again pick goroutine in FIFO order. type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } The same mechanism is used for Mutexes, Timers and Network IO. If a goroutine is blocked on the system call then the situation is differnt because we don’t know what is happing in the kernel space. Channels are created in the user space so we have full control over it but in the case of system call we don’t have. Blocking system call will block goroutine and underline kernel thread as well. Let’s suppose that one goroutine is made a syscall which is scheduled on one kernel thread, when a kernel thread is complete is execution it will wake up another kernel thread(thread reuse) that will pick up another goroutine and start executing it.This is a ideal scenario but in real case we don’t know how much time syscall will take so we can’t relay on the kernel thread to wake up another thread, we need some code level logic which will decide when to wake up another thread in case of syscall. This logic is implemented in golang as runtime·entersyscall()(line 2) and runtime·exitsyscall() (line 18). which means number of kernel thread can be more than number of core. System call code snippet of golang 1.19 https://cs.opensource.google/go/go/+/refs/tags/go1.19:src/syscall/asm_linux_arm.s;l=18 TEXT ·seek(SB),NOSPLIT,$0-28 BL\truntime·entersyscall(SB) MOVW\t$SYS__LLSEEK, R7\t// syscall entry MOVW\tfd+0(FP), R0 MOVW\toffset_hi+8(FP), R1 MOVW\toffset_lo+4(FP), R2 MOVW\t$newoffset_lo+16(FP), R3 MOVW\twhence+12(FP), R4 SWI\t$0 MOVW\t$0xfffff001, R6 CMP\tR6, R0 BLS\tokseek MOVW\t$0, R1 MOVW\tR1, newoffset_lo+16(FP) MOVW\tR1, newoffset_hi+20(FP) RSB\t$0, R0, R0 MOVW\tR0, err+24(FP) BL\truntime·exitsyscall(SB) RET When the system call is made to the kernel then it has two decideding points, one is entry point and another one is exit point. How many kernel thread OS can supports ? In Linux Kernel this parameter is defined in the file /proc/sys/kernel/threads-max which is specific to perticular kernel. sh:~$ cat /proc/sys/kernel/threads-max 94751 Here, the output 94751 indicates that the kernel can execute a maximum of 94751 threads. How many goroutine per program Go can support ? There is no restriction built into the schedular for the number of goroutines. How many kernel thread per program GO can support ? The runtime limits each program to a maximum of 10,000threads by default. This value can be changed by calling the SetMaxThreads functionfrom the runtime/debug package. https://github.com/golang/go/blob/67d85ad00f9d9be0cc2bb1bb96d01c3d40dcb376/src/runtime/proc.go#L686 Conclusion Number of kernel thread can be more than number of core. #kernel Thread &gt;#Core lightweight goroutines handling of IO and syscalls parallel executions of goroutine scalable (All the kernel level thread try to acess gloabl run queue with mutex enable. So due to contention this is not easy to scale) M:N Threading Distributed Run Queue SchedulerTo solve the sclable problem where every thread is try to access the mutex at the same time, per thread local run queue is maintained. Per thread state (local run queue) Still have global run queue Local queue of runnable goroutines, accessed without lock. Global queue of runnable goroutines, require lock. Conclusion lightweight goroutines handling of IO and SystemCalls Parallel execution of goroutines Scalable Efficient (#threads &gt; #cores) If number of thread is more than number of cores than what is the problem ? In distributed run queue schedular we know that each thread is having their own local run queue which contains information about which goroutine going to be execute next.Also due to syscall, number of thread will increase and most of time their local run queue is empty. So if the number of threads are greater than number of cores than during the work stealing process each thread has to scan all the thread local run queue and most of time they are empty so if threads are more than this process is time consuming and the solution is not efficent so we need to limit thread scanning to a constant which is solve using M:P:N threading model. M:P:N Threading P represented Processor that are resource required to run the go code. Processor Struct Details https://github.com/golang/go/blob/63e129ba1c458db23f0752d106ed088a2cf38360/src/runtime/runtime2.go#L601 M represented worker thread, or machine. Machine Thread Struct Details https://github.com/golang/go/blob/63e129ba1c458db23f0752d106ed088a2cf38360/src/runtime/runtime2.go#L519 G represented goroutine. Goroutine Struct Details https://github.com/golang/go/blob/63e129ba1c458db23f0752d106ed088a2cf38360/src/runtime/runtime2.go#L407 Generally number of processor is same as number of logical Processor. Logical Processor is not same as physical processor. Processors are created before starting of the main go routine. How to check number of logical processors ? package main import ( \"fmt\" \"runtime\" ) func main() { fmt.Println(runtime.NumCPU()) } Distributed M:P:N Schedular During the syscall operation handoff of logical processor is performed. https://github.com/golang/go/blob/master/src/runtime/proc.go#L1486 During the work stealing only fixed number number of queue has to be scan because number of logical processors are limited. What is the next goroutine to run ? Go schedular will check in following order to pick next goroutine to execute Local Run Queue https://github.com/golang/go/blob/67d85ad00f9d9be0cc2bb1bb96d01c3d40dcb376/src/runtime/proc.go#L5981 Global Run Queue https://github.com/golang/go/blob/67d85ad00f9d9be0cc2bb1bb96d01c3d40dcb376/src/runtime/proc.go#L5662 Network poller https://github.com/golang/go/blob/67d85ad00f9d9be0cc2bb1bb96d01c3d40dcb376/src/runtime/netpoll_aix.go#L154 Work Stealing https://github.com/golang/go/blob/67d85ad00f9d9be0cc2bb1bb96d01c3d40dcb376/src/runtime/proc.go#L2942 Conclusion lightweight goroutines handling of IO and System calls Parallel execution of goroutines Scalable Efficient/Work stealing Limitations of Go schedular FIFO is Bad for locality principle No notion of goroutine priorities (unlike linux kernel) No strong preemption -&gt; no strong fairness or latency guarantees. It’s not aware of the system topology -&gt; no real locality. There is an old NUMA-aware scheduler proposal. Also a suggestion to use LIFO queue so its more likely to have data in that CPU cores cache. References https://medium.com/@ankur_anand/illustrated-tales-of-go-runtime-scheduler-74809ef6d19b https://www.morsmachine.dk/go-scheduler https://go.dev/src/runtime/proc.go Scalable Go Scheduler Design Doc Analysis of the Go runtime scheduler Go scheduler: Implementing language with lightweight concurrency" }, { "title": "Solving Modern Programming Challenges With Go", "url": "/posts/Solving-modern-programming-challenges-with-Go/", "categories": "", "tags": "", "date": "2022-08-17 00:00:00 +0530", "snippet": " Development speed Consequently, many Go applications compile in under a second. The entire Go source tree compiles in under 20 seconds on modern hardware. Writing applications in dynamic languages makes you productive quickly becausethere are no intermediate steps between writing code and executing it. The trade-offis that dynamic languages don’t offer the type safety that static languages do and oftenneed a comprehensive test suite to avoid discovering incorrect type bugs at runtime Concurrency Go’s concurrency support is one of its strongest features. Goroutines are likethreads, but use far less memory and require less code to use. Channels are data structures that let you send typed messages between goroutines with synchronization builtin. Goroutines In other languages, you’d use threads to accomplish thesame thing, but in Go many goroutines execute on a single thread In other languages, you’d use threads to accomplish thesame thing, but in Go many goroutines execute on a single thread Channels Channels are data structures that enable safe data communication between goroutines. Channels help you to avoid problems typically seen in programming languagesthat allow shared memory access The hardest part of concurrency is ensuring that your data isn’t unexpectedlymodified by concurrently running processes, threads, or goroutines. Channels help to enforce the pattern that only one goroutine should modify the data at any time. This safe exchange of data between goroutines requires no other locks or synchronization mechanisms. Go’s Type System It’s still object-oriented development, but without the traditional headaches. Go developers simply embed types to reuse functionality in a design patterncalled composition. Many interfaces in Go’s standard library arevery small, exposing only a few functions. You don’t even need todeclare that you’re implementing an interface; you just need to write the implementation, You don’t need to declare that you’re implementing, an interface in Go; the compiler does the work of determining whether values of yourtypes satisfy the interfaces you’re using. Memory Management Go has a modern garbage collector that does thehard work for you. It isn’talways easy to track a piece of memory when it’s no longer needed; threads and heavyconcurrency make it even harder. Summary Go is modern, fast, and comes with a powerful standard library. Go has concurrency built in. Go uses interfaces as the building blocks of code reuse. " }, { "title": "Array Slice And Map In Golang", "url": "/posts/Array-Slice-And-Map-in-Golang/", "categories": "", "tags": "", "date": "2022-08-10 00:00:00 +0530", "snippet": " Array Array Internals and fundamentals An array in Go is a fixed-length data type that contains a contiguous block of elements of the same type. Arrays are valuable data structures because the memory is allocated sequentially. Having memory in a contiguous form can help to keep the memory you use stay loaded within CPU caches longer. An array is a value in Go. This means you can use it in an assignment operation. Thevariable name denotes the entire array and, therefore, an array can be assigned toother arrays of the same type. When an array is initialized in Go, eachindividual element that belongs to the array is initialized to its zero value. Declaring and Initializing Declare an integer array of five elements var array [5]int Array literals allow you to declare the number of elements you need and specify values for thoseelements Declaring and Initialize an array using an array literal array := [5]int{10, 20, 30, 40, 50} Declaring and Initialize an array with Go calculating size array := [...]int{10, 20, 30, 40, 50} Declaring an array initializing specific elements array := [5]int{1: 10, 2: 20} Declaring two-dimensional arrays var array [4][2]int Passing arrays between functions Passing an array between functions can be an expensive operation in terms of memory and performance. When your variable is an array, this means the entire array, regardlessof its size, is copied and passed to the function. Slice Slice internals and fundamentals Slices are built around the concept of dynamic arrays that can grow andshrink They’re three field data structures that contain the metadata. The three fields are a pointer to the underlying array, the length or the number of elements the slice has access to, and the capacity or the number of elements the slice hasavailable for growth. Remember, if you specify a value inside the [ ] operator, you’re creating an array. Ifyou don’t specify a value, you’re creating a slice. Create an array of three integers. array := [3]int{10, 20, 30} Create a slice of integers with a length and capacity of three. slice := []int{10, 20, 30} Creating and Initializing When you use make, oneoption you have is to specify the length of the slice. Declaring a slice of strings by length slice := make([]string, 5) Declaring a slice of integers by length and capacity slice := make([]int, 3, 5) Contains a length of 3 and has a capacity of 5 elements. Trying to create a slice with a capacity that’s smaller than the length is not allowed Declaring a slice with a slice literal slice := []string{\"Red\", \"Blue\", \"Green\", \"Yellow\", \"Pink\"} NIL and empty slices Declaring an nil slice. var slice []int A nil slice is createdby declaring a slice without any initialization. Declaring an empty slice slice := make([]int, 0) slice := []int{} NIL useful when you want to represent a slice that doesn’t exist, such as when an exceptionoccurs in a function that returns a slice. Empty slices are useful when you want to represent an empty collection, such as whena database query returns zero results . Regardless of whether you’re using a nil slice or an empty slice, the built-in functionsappend, len, and cap work the same. Working with slices Slices are called such because you can slice a portion of the underlying array to createa new slice. slice := []int{10, 20, 30, 40, 50} newSlice := slice[1:3] Changes made to the shared section of the underlying array by one slice can beseen by the other slice. Calculating Length and Capacity of Slice For slice[i:j:k] or [2:3:4] Length: j - i or 3 - 2 = 1 Capacity: k - i or 4 - 2 = 2 To use append, you need a source slice and a value that is to be appended. Whenyour append call returns, it provides you a new slice with the changes.The append function will always increase the length of the new slice. func main() { slice := []int{10,20,30,40,50} newSlice := slice[1:3] fmt.Println(slice) fmt.Println(newSlice) newSlice =append(newSlice,60) fmt.Println(slice) fmt.Println(newSlice) } [10 20 30 40 50] [20 30] [10 20 30 60 50] [20 30 60] Because there was available capacity in the underlying array for newSlice, theappend operation incorporated the available element into the slice’s length andassigned the value. Since the original slice is sharing the underlying array, slice also changed. When there’s no available capacity in the underlying array for a slice, the append function will create a new underlying array, copy the existing values that are being referenced, and assign the new value func main() { slice := []int{10,20,30,40} newSlice :=append(slice,60) fmt.Println(slice) fmt.Println(newSlice) } [10 20 30 40] [10 20 30 40 60] By having the option to set the capacity of a new slice to be the same as the length,you can force the first append operation to detach the new slice from the underlyingarray. Detaching the new slice from its original source array makes it safe to change. newSlice len=1 and capacity=2 func main() { slice := []string{\"Apple\", \"Orange\", \"Plum\", \"Banana\", \"Grape\"} newSlice :=slice[2:3:4] fmt.Println(slice) fmt.Println(newSlice) newSlice =append(newSlice,\"mango\") fmt.Println(slice) fmt.Println(newSlice) } [Apple Orange Plum Banana Grape] [Plum] [Apple Orange Plum mango Grape] [Plum mango] newSlice len=1 and capacity=1 func main() { slice := []string{\"Apple\", \"Orange\", \"Plum\", \"Banana\", \"Grape\"} newSlice :=slice[2:3:3] fmt.Println(slice) fmt.Println(newSlice) newSlice =append(newSlice,\"mango\") fmt.Println(slice) fmt.Println(newSlice) } [Apple Orange Plum Banana Grape] [Plum] [Apple Orange Plum Banana Grape] [Plum mango] Iterating over slices Go has a special keywordcalled range that you use in conjunction with the keyword for to iterate over slices. //Create a slice of integers. // Contains a length and capacity of 4 elements. slice := []int{10, 20, 30, 40} // Iterate over each element and display each value. for index, value := range slice { fmt.Printf(\"Index: %d Value: %d\\n\", index, value) } The first valueis the index position and the second value is a copy of the value in that index position. It’s important to know that range is making a copy of the value, not returning a reference If you don’t need the index value, you can use the underscore character to discardthe value. // Create a slice of integers. // Contains a length and capacity of 4 elements. slice := []int{10, 20, 30, 40} // Iterate over each element and display each value. for _, value := range slice { fmt.Printf(\"Value: %d\\n\", value) } The keyword range will always start iterating over a slice from the beginning. If youneed more control iterating over a slice, you can always use a traditional for loop. // Create a slice of integers. // Contains a length and capacity of 4 elements. slice := []int{10, 20, 30, 40} // Iterate over each element starting at element 3. for index := 2; index &lt; len(slice); index++ { fmt.Printf(\"Index: %d Value: %d\\n\", index, slice[index]) } Passing slices between functions Passing a slice between two functions requires nothing more than passing the slice by value.Since the size of a slice(address, Length, Capacity) is small, it’s cheap to copy and pass between functions. The data associated with a slice is contained in the underlying array, there are no problems passing a copy of a slice to any function. Only the slice is being copied, not theunderlying array slice := make([]int, 1e6) // Pass the slice to the function foo. slice = foo(slice) // Function foo accepts a slice of integers and returns the slice back. func foo(slice []int) []int { //code logic return slice } On a 64-bit architecture, a slice requires 24 bytes of memory while passing to functions.The pointer fieldrequires 8 bytes, and the length and capacity fields require 8 bytes respectively Map Map internals and fundamentals A map is a data structure that provides you with an unordered collection of key/value pairs. The strength of a map is its ability toretrieve data quickly based on the key. A key works like an index, pointing to the valueyou associate with that key. Maps are unordered collections, and there’s no way to predict the order inwhich the key/value pairs will be returned, this isbecause a map is implemented using a hash table. Creating and Initializing You can use the builtin function make, or you can use a map literal. Declaring a map var mp map[string]int Declaring and Initializing a map using make mp := make(map[string]int) Delcaring and Initializing a map using literal mp := map[string]string{\"Red\": \"#da1337\", \"Orange\": \"#e95a22\"} Slices, functions, and struct types thatcontain slices can’t be used as map keys. dict := map[[]string]int{} // compiler error There’s nothing stopping you from using a slice as a map value. dict := map[int][]string{} Working with maps Assiging values to a map // Create an empty map to store colors and their color codes. colors := map[string]string{} // Add the Red color code to the map. colors[\"Red\"] = \"#da1337\" Runtime error assigned to a nil map // Create a nil map by just declaring the map. var colors map[string]string // Add the Red color code to the map. colors[\"Red\"] = \"#da1337\" Runtime Error: panic: runtime error: assignment to entry in nil map Retrieving a value from a map and testing existence. // Retrieve the value for the key \"Blue\". value, exists := colors[\"Blue\"] // Did this key exist? if exists { fmt.Println(value) } Wrong way of checking existence of Key // Retrieve the value for the key \"Blue\". value := colors[\"Blue\"] // Did this key exist? if value != \"\" { fmt.Println(value) } When you index a map in Go, it will always return a value, even when the key doesn’texist. In this case, the zero value for the value’s type is returned. Iterating over a map using for range // Create a map of colors and color hex codes. colors := map[string]string{ \"AliceBlue\": \"#f0f8ff\", \"Coral\": \"#ff7F50\", \"DarkGray\": \"#a9a9a9\", \"ForestGreen\": \"#228b22\", } // Display all the colors in the map. for key, value := range colors { fmt.Printf(\"Key: %s Value: %s\\n\", key, value) } Removing an item from a map delete(colors, \"Coral\") Passing maps between functions Passing a map between two functions doesn’t make a copy of the map. you canpass a map to a function and make changes to the map, and the changes will bereflected by all references to the map. func main() { mp :=map[int]int{ 10:1, 20:2, 30:3, 40:4, 50:5, } fmt.Println(mp) removeKey(mp,20) fmt.Println(mp) } func removeKey(mp map[int]int, key int){ delete(mp,key) } output:- map[10:1 20:2 30:3 40:4 50:5] map[10:1 30:3 40:4 50:5] Summary Arrays are the building blocks for both slices and maps. Slices are the idiomatic way in Go you work with collections of data. Maps arethe way you work with key/value pairs of data. The built-in function make allows you to create slices and maps with initiallength and capacity. Slice and map literals can be used as well and support setting initial values for use. Slices have a capacity restriction, but can be extended using the built-in function append. Maps don’t have a capacity or any restriction on growth. The built-in function len can be used to retrieve the length of a slice or map. The built-in function cap only works on slices. Through the use of composition, you can create multidimensional arrays andslices. You can also create maps with values that are slices and other maps. Aslice can’t be used as a map key. Passing a slice or map to a function is cheap and doesn’t make a copy of theunderlying data structure. " }, { "title": "Authentication Service", "url": "/posts/Auth/", "categories": "Golang, Go", "tags": "go, golang, api, docker, jwt", "date": "2022-02-05 00:00:00 +0530", "snippet": "DockerHub Profile: https://hub.docker.com/repository/docker/pilaniya1337/authservice GitHub Profile:https://github.com/mukeshpilaniya/authMakeFile Start the application make up Stop the application make stop Build docker images form source code make docker-build RestAPI call endpoints1. Create User Endpoint url:- http://localhost:8081/api/v1/create_user Request Type-POST method Example: Request:- http://localhost:8081/api/v1/create_user { \"first_name\": \"mukesh\", \"last_name\": \"pilaniya\", \"email\": \"test@gmail.com\", \"password\": \"pilaniya\" } Response:- { \"id\": \"bf325346-ab3f-11ec-8284-86023e8131c0\", \"first_name\": \"mukesh\", \"last_name\": \"pilaniya\", \"email\": \"test@gmail.com\", \"password\": \"pilaniya\", \"is_verified\": false, \"created_at\": \"0001-01-01T00:00:00Z\", \"updated_at\": \"0001-01-01T00:00:00Z\" }2. Generate Token Endpoint url:- http://localhost:8081/api/v1/generate_token Request Type-POST method Example: Request:- http://localhost:8081/api/v1/generate_token { \"email\": \"test@gmail.com\", \"password\": \"pilaniya\" } Response:- { \"message\": \"token generated\", \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImI5NDBiMjhjLTczYTgtNDJjNS05ZjczLWYxODg4YmJlNjlkYSIsInVzZXJfaWQiOiJiZjMyNTM0Ni1hYjNmLTExZWMtODI4NC04NjAyM2U4MTMxYzAiLCJpc3MiOiJwaWxhbml5YS5hdXRoLnNlcnZpY2UiLCJpc3N1ZWRfYXQiOjE2NDgxMDU0NzgsImV4cGlyZWRfYXQiOjE2NDgxMDU1OTgsImNsYWltcyI6e319.4k1PNH3Mxthw5NEF4RDepMLlYMnkOpYfOIHw49b9ocE\", \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjA2Nzk5MzUwLTAzZTQtNDhhOS05NmNlLTJiOWYyYTU4NzViOCIsInVzZXJfaWQiOiJiZjMyNTM0Ni1hYjNmLTExZWMtODI4NC04NjAyM2U4MTMxYzAiLCJpc3MiOiJwaWxhbml5YS5hdXRoLnNlcnZpY2UiLCJpc3N1ZWRfYXQiOjE2NDgxMDU0NzgsImV4cGlyZWRfYXQiOjE2NDgxMDYwNzgsImNsYWltcyI6e319.1LowDhPuKm46nQXPZ7Wp2RihOfiFEUE9edr43vm5ogU\" }3. Get User by Id Endpoint url:- http://localhost:8081/api/v1/get_user Request Type-POST method Example: Request:- http://localhost:8081/api/v1/get_user Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImI5NDBiMjhjLTczYTgtNDJjNS05ZjczLWYxODg4YmJlNjlkYSIsInVzZXJfaWQiOiJiZjMyNTM0Ni1hYjNmLTExZWMtODI4NC04NjAyM2U4MTMxYzAiLCJpc3MiOiJwaWxhbml5YS5hdXRoLnNlcnZpY2UiLCJpc3N1ZWRfYXQiOjE2NDgxMDU0NzgsImV4cGlyZWRfYXQiOjE2NDgxMDU1OTgsImNsYWltcyI6e319.4k1PNH3Mxthw5NEF4RDepMLlYMnkOpYfOIHw49b9ocE { \"id\": \"bf325346-ab3f-11ec-8284-86023e8131c0\" } Response:- { \"id\": \"bf325346-ab3f-11ec-8284-86023e8131c0\", \"first_name\": \"mukesh\", \"last_name\": \"pilaniya\", \"email\": \"test@gmail.com\", \"password\": \"pilaniya\", \"is_verified\": false, \"created_at\": \"2022-03-24T12:28:02.068075Z\", \"updated_at\": \"2022-03-24T12:28:02.068075Z\" }4. Generate Access Token Form Refresh Token Endpoint url:- http://localhost:8081/api/v1/generate_access_token Request Type-POST method Example: Request:- http://localhost:8081/api/v1/generate_access_token { \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjA2Nzk5MzUwLTAzZTQtNDhhOS05NmNlLTJiOWYyYTU4NzViOCIsInVzZXJfaWQiOiJiZjMyNTM0Ni1hYjNmLTExZWMtODI4NC04NjAyM2U4MTMxYzAiLCJpc3MiOiJwaWxhbml5YS5hdXRoLnNlcnZpY2UiLCJpc3N1ZWRfYXQiOjE2NDgxMDU0NzgsImV4cGlyZWRfYXQiOjE2NDgxMDYwNzgsImNsYWltcyI6e319.1LowDhPuKm46nQXPZ7Wp2RihOfiFEUE9edr43vm5ogU\" } Response:- {\t\"message\": \"Access token generated\",\t\"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImY2MTYwZmI2LTY3ODgtNDI5Zi04ZjEwLWE4NTMyOTIxYjA4YiIsInVzZXJfaWQiOiJiZjMyNTM0Ni1hYjNmLTExZWMtODI4NC04NjAyM2U4MTMxYzAiLCJpc3MiOiJwaWxhbml5YS5hdXRoLnNlcnZpY2UiLCJpc3N1ZWRfYXQiOjE2NDgxMDU3OTEsImV4cGlyZWRfYXQiOjE2NDgxMDU5MTEsImNsYWltcyI6e319.E9GotSTOh6Gqn1Oupv_X4_a9IoTtF5pvyAjXKkC3_Ok\" }" }, { "title": "Open Source Contributions", "url": "/posts/Open-Source-Contributions/", "categories": "", "tags": "", "date": "2021-06-05 00:00:00 +0530", "snippet": "Open Source Contribution List Checkmarx/kics 1.1\thttps://github.com/Checkmarx/kics/pull/3422 1.2\thttps://github.com/Checkmarx/kics/issues/3412 Canvasbird/canvasboard 2.1 \thttps://github.com/Canvasbird/canvasboard/issues/350 " }, { "title": "Cp Competitive programming time Complexity", "url": "/posts/CP-competitive-programming-time-complexity/", "categories": "Competitive Programming, Time Complexity", "tags": "cp", "date": "2021-05-15 00:00:00 +0530", "snippet": "Hello all, when you doing competitive programming or solving any coding questions on coding platform like leetcode, hackerearth or hackerrank then sometime you might be faced TLE error, while submitting your code on online judges. So today, I will talk about how you can train your mind before solving any coding problems and can get rid of TLE error. I’m sharing my personal experiences this might be useful for you, while solving online assessment on hackerrank and hackerearth.For this table construction i have assumed that on average online judge will be able to finished 10^6 Instruction per second. Range of N Allowed Time Complexity Most Used tech N≤10 O(N!) Brute Force N≤25 O(2^N) Recursion/Brute force/Backtracking N≤100 O(N^4)   N≤500 O(N^3)   N≤5*10^3 O(N^2) 2D-dp table construction/Brute force-two for loop N≤5*10^5 O(N√(N)),O(N Log(N)) Sorting/Binary search N≤10^6 O(N), O(N Log(N)) Prefixarray/Suffixarray/Sorting/1D-dp N≤10^7 Optimized O(N),Optimized O(N Log(N)), O(N Log(Log(n))), O(Log(N))   N≤10^8 O(Log(N))   N≤10^9 O(Log(N)) Binary Search N≤10^12 O(√N)   N≤10^16 Optimized O(√N) Bit mapping N≤10^18 O(Log(N)) Bit mapping " }, { "title": "Calculator With Devops Tool Chain", "url": "/posts/Calculator-With-DevOps-Tool-Chain/", "categories": "Docker, Springboot, Jenkins, ELK", "tags": "java, hibernate, jenkins, elk, docker", "date": "2020-04-12 00:00:00 +0530", "snippet": "DockerHub Profile: https://hub.docker.com/r/pilaniya1337/calculator GitHub Profile:https://github.com/mukeshpilaniya/calculatorRequired Tools: - Git (source code management) Docker (container node) Eclipse /IntelliJ (Project IDE) Jenkins (Continuous Integration: git, Continuous testing: Junit) Maven (Continuous Build) Rundeck (continuous deployment) ELK (elastic search, Logstash, Kibana: continuous monitoring)Installing Git: -sudo apt-get install gitInstalling Docker: -sudo apt-get updatesudo apt install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key addsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"sudo apt updatesudo apt install docker-cesudo usermod -aG docker ${USER}Installing Eclipse IDE:- https://www.eclipse.org/downloads/Installing Jenkins: - Download the war filehttp://mirrors.jenkins.io/war-stable/latest/jenkins.war Run the war file java -jar jenkins.war Got to url http://localhost:8080Jenkins Plugins: - Rundeck plugin Docker plugin Logstash pluginConfigure plugin:-Logstash plugin automatically create calculator index in elasticsearchInstalling Maven: - sudo apt install maven mvn -versionInstalling Rundeck: - Download rundeck fromhttps://download.rundeck.org/deb/rundeck_3.2.6.20200427-1_all.deb install using dpkgdpkg -i rundeck\\_3.2.6.20200427-1\\_all.deb Rundeck start and stop commandsudo service rundeckd startsudo service rundeckd stop Default address, username, passwordDefault address: http://localhost:4440default username and password: admin Allow rundeck to execute sudo commands on system terminal without password enter super user mode open file visudosudo visudo Add following lines at end of the file rundeck ALL=(ALL) NOPASSWD: ALL Localhost ALL=(ALL) NOPASSWD: ALL Create a new Project and job in Rundeck:- Go to the url http://localhost:4440 and create a new project name as calculator and save it. Create a new job in the same project, enter jobname and job group Navigate to workflow section and add the following commands to execute on registered node command 1 to replace old jar file with new jar filesudo docker cp /var/lib/jenkins/workspace/Calculator\\ Build/target/Calculator.jar calculator:/ Command 2 to start calculator containersudo docker start calculator Command 3 to pass argument to calculator jar filesudo docker exec -t calculator java -cp calculator.jar org.iiitb.calculator.App 3 4 2 Under Nodes select execute locally because all these commands will be executed on the local system. Make note of UUID for future reference and save the job.ELK Installing: -Step 1 installing elasticsearch: - Set java 8 as default java versionAllow rundeck to execute sudo commands on system terminal without password enter super user mode open file visudo sudo visudo Add following lines at end of the file rundeck ALL=(ALL) NOPASSWD: ALLLocalhost ALL=(ALL) NOPASSWD: ALL download Elasticsearch followed by public signing keysudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - install the apt-transport-https packagesudo apt-get install apt-transport-https Add the repositoryecho \"deb https://artifacts.elastic.co/packages/6.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list Update the repo list and install the packagesudo apt-get updatesudo apt-get install elasticsearch Update the repo list and install the packagesudo vim /etc/elasticsearch/elasticsearch.yml Uncomment \"network.host\" and \"http.port\". Following configuration should be addednetwork.host: localhosthttp.port: 9200 Start ElasticSearchsudo systemctl start elasticsearch.serviceStep 2 installing kibana:- Let's start installing Kibana now and modify Kibana settingssudo apt-get install kibanasudo vim /etc/kibana/kibana.yml Uncomment following lines:server.port: 5601server.host: \"localhost\"elasticsearch.url: http://localhost:9200 start Kibana servicesudo systemctl start kibana.service Goto http://localhost:5601Step 3 installing logstash: - sudo apt-get install logstash sudo service logstash start Got to http://localhost:4440http://localhost:9200SDLC: -Development Phase: -The development of this project is happened in java and it is a maven-based project. The src/main/java directory contains the project source code and the src/test/java directory contains the test cases like unit testing.The next step is executing these commands: -mvn clean - command attempt to clean target folder files that are generated during the build by mavenmvn package - command convert the entire maven project into an executable jar packagePom xml file: -To perform unit testing we have to add Junit dependency and maven-jar-plugin for creating a package. It will create a package with a name calculator.After executing these commands, a target folder is generated automatically which contains our artifacts file calculator.jar. To test this artifact, copy this artifacts file and run the below command in the same directory.java -cp calculator.jar org.iiitb.calculator.App org.iiitb.calculator is a package name and App is a class name where calculator methods are defined.Docker file: -create a 'Dockerfile' under project level (at same level of pom.xml)# Start with a base image containing Java runtimeFROM openjdk:8# Add Maintainer InfoLABEL maintainer=\"github.com/mukeshpilaniya\"# Add a volume pointing to /tmpEXPOSE 8080# Add the application's jar to the containerADD /target/calculator.jar calculator.jar# Run the jar fileENTRYPOINT [\"java\",\"-cp\",\"calculator.jar\",\"org.iiitb.calculator.App\"]The next step is, create a repository(calculator) in github and push project code into calculator repository. The following set of commands will push the code into github repository.git initgit remote add origin \"https://github.com/mukeshpilaniya/calculator.git\"git add .git commit -m \"initial commit\"git push origin master.Build a docker Image: -Enter the following command in the terminal with the home directory of projectsudo docker build -t calculator\\_image .This command will create project specific docker image(calculator_image), now create a container of this image using the following commandsudo run --name calculator\\_container -d calculator\\_imageSoftware Development life cycle: -The whole project is developed following the DevOps model and using various tools. The software development Life Cycle of this project includes six stages Source Control Management (git) Code Building (maven) Code testing (Junit) Build and Publish Docker image (Docker) Deploying (Rundeck) Monitoring (ELK)Setup jenkins Pipeline:1. Job1: Calculator SCM:SCM stands for source code management and used for managing the source code of the application, for this project source code is stored in a git repository hosted on GitHub at mukeshpilaniya/calculator. Here we are using pollSCM which checks the git repository after an interval and if there is a change in the code it triggers the pipeline otherwise it doesn't do anything.Create a FreeStyle project names as calculator SCM and following is the configuration in this step2. Job2: Calculator Build:This step build triggers automatically when the first job is finished and it will build a jar file in the jenkins working directory if the build is successful it will automatically trigger the calculator Test job. Create a maven project name as calculator Build and following is the configuration in this step.3. Job3: CalculatorTest: -If the build is successful then the calculator test job will automatically be triggered. it will build the docker image and push it into dockerhub. This job will run test cases and send the control to the calculator deploy. Create a maven project name as calculator Test and Configuration of this step is as follows.Create a Maven Project and name its calculator Test4. Job4: calculator deploy: -This job will automatically trigger if the calculator test job is successfully executed and it will trigger the specified rundeck job.Create a FreeStyle project and name it as a calculator deploy. Configuration of this step is as follows.Rundeck instance: rundeckCopy the job UUID in job identifier id in Post Build Actions → RundeckCreate Pipeline View: -Click on + icon and do following configurationClick Ok and select calculator SCM as Initial Job under Pipeline Flow. Then click save.Pipeline View Layout: -Create index in kibana and Visualize through graph: - Go to url http://localhost:5601 To create kibana index pattern navigate to Management-&gt;under kibana section choose index pattern and create new index pattern name as \"calculator*\". Click on next step and choose @Timestamp options To see the log navigate to discover-&gt; select calculator as index pattern To visualize logs navigate to Visualize-&gt;click on + icon -&gt;select one of map type-&gt;select calculator* index -&gt;select appropriate fields-&gt;click on run-&gt;save -&gt;name as calculator 1Create 3-4 graph and save as calculator 1, calculator 2, calculator 3 To create a Dashboard of calculator, navigate to Dashboard &gt;click on add-&gt;in search bar type calculator it will show calculator 1,2 and 3 select all of these and save the dashboard name as Calculator.Results and execution: -When new features are introduced in a project, then from its building, testing, deployment and monitoring is done in an automated manner.We first write code for addition method and latter add subtract, multiplication and division method. output of each method as we added in our project codeConclusion: -DevOps tools help in automating the task of building, testing, releasing, deploying, operating and monitoring in a convenient and efficient way with enormous speed. Manual intervention prone to errors but automated environments are not. Data sharing techniques are used effectively to connect Devs with Ops.References: -[1] GitHub project: https://github.com/mukeshpilaniya/calculator[2] DockerHub profile: https://hub.docker.com/u/pilaniya1337" }, { "title": "Classroom Management System", "url": "/posts/Classroom-Management-System/", "categories": "DevOps, Springboot", "tags": "devops, jenkins, springboot, docker", "date": "2020-03-12 00:00:00 +0530", "snippet": "Github:- https://github.com/mukeshpilaniya/cmsLoginOnly Admin, Prof, SAC,TAs, Committees can loginAdmin Enter timetable details in database(Fixed for the sem) If a particular classroom (which is not available)is required for some event, admin has to reschedule the class to some other room according to capacity required and inform professor about the change Grant or reject the requests by professors, SAC, Committees, TAs(by considering the purpose) After granting, notify the prof/SAC/Committees with all details of the room. Also, notify the cleaning staff to clean the room before the class/event starts(If asked for while requesting for classroom). Also, Notify Security to open the room for cleaning and class/event as well. If a request is rejected, notify Prof/SAC, committees that their request was rejected.Professor View Classrooms available according to filters like building(Ramanujan, Aryabhatta), minimum capacity required, time slot and purpose of asking for room request. They will have an option to notify the cleaning staff if the classroom is granted and if they want that room to be cleaned. Purpose can be: Event ( Then show all rooms as rescheduling is an option) Exams( Show classrooms according to the fact that students capacity should be double the no. of students registered in course. ) Extra class(Normal classroom availability) Meeting with SAC/Committees/TAs SAC, Committees, TAs Request for rooms according to capacity required, purpose, time slot Ask for cleaning the room before slot time.(Optional) Purpose can be: Meeting within Committee Interaction with Students Interaction with prof. (In this case, the prof has to request for room.) Database SchemaMysql ContainerSetuppull the mysql docker image from docker hubdocker pull mysql:5.7.29create cms-mysql containerdocker run --name cms-mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=cms_db -e MYSQL_USER=cms_user -e MYSQL_PASSWORD=cms_password -d mysql:5.7.29Springboot ContainerSetup to build projectbuild cms-springboot docker imagedocker build -t cms-springboot .create cms-springboot container from docker imagedocker run -t -p 8082:8082 --name cms-springboot --link cms-mysql:mysql -d cms-springbootSpringboot ContainerSetup without building Projectpull the springboot-cms docker image from docker hubdocker pull pilaniya1337/cmscreate cms-springboot container from docker imagedocker run -t -p 8082:8082 --name cms-springboot --link cms-mysql:mysql -d pilaniya1337/cmsWorking ScreenshotGo to:- http://loaclhost:8082 username- admin password- admin " }, { "title": "Flight Ticket Reservation", "url": "/posts/Flight-Ticket-Reservation/", "categories": "Springboot, MySql", "tags": "java, hibernate, mysql", "date": "2020-02-17 00:00:00 +0530", "snippet": "Github:- https://github.com/mukeshpilaniya/FlightApiFlight Ticket ReservationDescriptionDesign and implement an application to reserve flights based on source, destination and date. The application should take care of the following aspects:• Repository of flight information containing airline name, flight number, source, destination, start time, end time, frequency (days on which the flight is active), total number of seats in the aircraft(capacity)• Ability to search for flights based on source, destination anddate• Reserve 'n'numberof seats on a particular fight based on availability of seats.APIs:1. Search for flights based on source, destination anddate2. Userbeingabletoreserve'n'numberofseatsonaparticularfight(thisAPI should keep availability of seats on that flight inmind)3. View reservations for a users (both past andupcoming)Expectation:• Clean professional levelCode• Modelling of core entities and relationships betweenthem.• Your code needs to be demonstrable. To do this, you can need to have an API based solution either as a WebApp, MobileApp or even providebasic API calls to run through the above mentionedworkflows.• Workflows for creation of flight repository are not required. This could be pre- loaded as a part of applicationstartup.• User Identification but notauthentication• Backend Database is optional. However modelling should becompleteProject infoServer url- http://localhost:8080Database- MysqlJava version- 1.8.0_242Project Type- MavenFramework- spring bootDependencies- spring web,spring data Jparun these commands to setup mysql database for application before running the application jar-- drop database if exitsDROP DATABASE IF EXISTS flight_db;-- create database nameCREATE DATABASE flight_db;-- create user with passwordCREATE USER 'flight_user'@'localhost' IDENTIFIED BY 'flight_password';-- provide all the permissionGRANT ALL PRIVILEGES ON flight_db. * TO 'flight_user'@'localhost';Dummy data for application-- Dummy data for airport tableINSERT INTO `flight_db`.`airport` (`airport_id`, `airport_city`, `airport_code`, `airport_name`) VALUES ('1', 'jaipur', 'JP', 'jaipur');INSERT INTO `flight_db`.`airport` (`airport_id`, `airport_city`, `airport_code`, `airport_name`) VALUES ('2', 'delhi', 'NCR', 'delhi');INSERT INTO `flight_db`.`airport` (`airport_id`, `airport_city`, `airport_code`, `airport_name`) VALUES ('3', 'bangalore', 'BNG', 'bangalore');INSERT INTO `flight_db`.`airport` (`airport_id`, `airport_city`, `airport_code`, `airport_name`) VALUES ('4', 'pune', 'PU', 'pune');INSERT INTO `flight_db`.`airport` (`airport_id`, `airport_city`, `airport_code`, `airport_name`) VALUES ('5', 'sikar', 'SIK', 'sikar');-- Dummy data for flight tableINSERT INTO `flight_db`.`flight` (`flight_id`, `flight_number`, `flight_name`, `number_of_seats`) VALUES ('1', '101', 'AIRIndia', '55');INSERT INTO `flight_db`.`flight` (`flight_id`, `flight_number`, `flight_name`, `number_of_seats`) VALUES ('2', '102', 'GoAIR ', '45');INSERT INTO `flight_db`.`flight` (`flight_id`, `flight_number`, `flight_name`, `number_of_seats`) VALUES ('3', '103', 'AIRindia', '60');INSERT INTO `flight_db`.`flight` (`flight_id`, `flight_number`, `flight_name`, `number_of_seats`) VALUES ('4', '104', 'Indigo', '55');INSERT INTO `flight_db`.`flight` (`flight_id`, `flight_number`, `flight_name`, `number_of_seats`) VALUES ('5', '105', 'GoAIR', '50');-- Dummy data for flight_schedule tableINSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('1', '2020-11-02 10:00:00', '1', '2020-11-02 09:00:00', '1', '1', '3');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('2', '2020-11-02 11:00:00', '1', '2020-11-02 09:00:00', '1', '1', '4');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('3', '2020-11-03 10:30:00', '2', '2020-11-03 09:00:00', '1', '1', '3');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('4', '2020-11-04 11:25:00', '3', '2020-11-04 10:00:00', '1', '2', '5');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('5', '2020-11-03 09:00:00', '2', '2020-11-03 08:00:00', '2', '1', '3');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('6', '2020-11-03 10:00:00', '2', '2020-11-03 08:00:00', '2', '1', '5');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('7', '2020-11-05 11:50:00', '4', '2020-11-05 11:25:00', '3', '2', '4');INSERT INTO `flight_db`.`flight_schedule` (`schedule_id`, `arrival_time`, `day_of_the_week`, `departure_time`, `flight_id`, `from_flight_airport`, `to_flight_airport`) VALUES ('8', '2020-11-05 09:40:00', '4', '2020-11-05 08:30:00', '4', '3', '1');-- Dummy data for user tableINSERT INTO `flight_db`.`user` (`id`, `email`, `name`, `phone_number`, `user_name`) VALUES ('1', 'pilaniya@iiitb.org', 'mukesh', '123456789', 'pilaniya');INSERT INTO `flight_db`.`user` (`id`, `email`, `name`, `phone_number`, `user_name`) VALUES ('2', 'pilaniya1@iiitb.org', 'rohit', '123456789', 'pilaniya1');INSERT INTO `flight_db`.`user` (`id`, `email`, `name`, `phone_number`, `user_name`) VALUES ('3', 'pilaniya2@iiitb.org', 'sumit', '123456789', 'pilaniya2');INSERT INTO `flight_db`.`user` (`id`, `email`, `name`, `phone_number`, `user_name`) VALUES ('4', 'pilaniya3@iiitb.org', 'rakesh', '123456789', 'pilaniya3');-- Dummy data for ticket tableINSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('1', '2020-11-02', '101', 'jaipur', '2', 'bangalore', '1');INSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('2', '2020-11-09', '101', 'jaipur', '2', 'bangalore', '1');INSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('3', '2020-11-02', '101', 'jaipur', '1', 'bangalore', '1');INSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('4', '2020-11-02', '101', 'jaipur', '2', 'bangalore', '1');INSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('5', '2020-11-03', '102', 'jaipur', '15', 'bangalore', '1');INSERT INTO `flight_db`.`ticket` (`ticket_id`, `date`, `flight_number`, `source`, `reserve_seat`, `destination`, `user_id`) VALUES ('6', '2020-11-02', '101', 'jaipur', '5', 'bangalore', '1');run applicationeither you can build project using maven package or run java -jar flight-0.0.1-SNAPSHOT.jartables in flight_db+---------------------+| Tables_in_flight_db |+---------------------+| airport || flight || flight_schedule || ticket || user |+---------------------+-- user table+--------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+----------------+| id | bigint(20) | NO | PRI | NULL | auto_increment || email | varchar(255) | YES | | NULL | || name | varchar(255) | YES | | NULL | || phone_number | bigint(20) | YES | | NULL | || user_name | varchar(255) | YES | | NULL | |+--------------+--------------+------+-----+---------+----------------+--flight table+-----------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-----------------+--------------+------+-----+---------+----------------+| flight_id | bigint(20) | NO | PRI | NULL | auto_increment || flight_number | bigint(20) | YES | | NULL | || flight_name | varchar(255) | YES | | NULL | || number_of_seats | bigint(20) | YES | | NULL | |+-----------------+--------------+------+-----+---------+----------------+-- airport table+--------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+----------------+| airport_id | bigint(20) | NO | PRI | NULL | auto_increment || airport_city | varchar(255) | YES | | NULL | || airport_code | varchar(255) | YES | | NULL | || airport_name | varchar(255) | YES | | NULL | |+--------------+--------------+------+-----+---------+----------------+-- flight_schedule table+---------------------+------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------------------+------------+------+-----+---------+----------------+| schedule_id | bigint(20) | NO | PRI | NULL | auto_increment || arrival_time | datetime | YES | | NULL | || day_of_the_week | int(11) | YES | | NULL | || departure_time | datetime | YES | | NULL | || flight_id | bigint(20) | YES | MUL | NULL | || from_flight_airport | bigint(20) | YES | MUL | NULL | || to_flight_airport | bigint(20) | YES | MUL | NULL | |+---------------------+------------+------+-----+---------+----------------+-- ticket table+---------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------------+--------------+------+-----+---------+----------------+| ticket_id | bigint(20) | NO | PRI | NULL | auto_increment || date | date | YES | | NULL | || flight_number | bigint(20) | YES | | NULL | || source | varchar(255) | YES | | NULL | || reserve_seat | bigint(20) | YES | | NULL | || destination | varchar(255) | YES | | NULL | || user_id | bigint(20) | YES | MUL | NULL | |+---------------+--------------+------+-----+---------+----------------+RestAPI call endpoints1. register user Endpoint url:- http://localhost:8080/user/addRequest Type-POST methodExample:Request:- http://localhost:8080/user/add/{ \"name\": \"pilaniya1\", \"userName\": \"iceman\", \"email\": \"pilaniya1@iiitb.org\", \"phoneNumber\": 982688344}Response:-{ \"id\": 5, \"name\": \"pilaniya5\", \"userName\": \"pilaniya5\", \"email\": \"pilaniya5@iiitb.org\", \"phoneNumber\": 123456789}2. search flightEndpoint Url:- http://localhost:8080/flight/search/{source}/{destination}/{date}Request Type-GET methodExample:Request:- http://localhost:8080/flight/search/jaipur/bangalore/2020-11-23Response:-[ { \"id\": 1, \"flight\": { \"id\": 1, \"flightno\": 101, \"name\": \"AIRIndia\", \"numberOfSeats\": 55 }, \"fromFlightAirport\": { \"id\": 1, \"name\": \"jaipur\", \"code\": \"JP\", \"city\": \"jaipur\" }, \"toFlightAirport\": { \"id\": 3, \"name\": \"bangalore\", \"code\": \"BNG\", \"city\": \"bangalore\" }, \"day\": \"MONDAY\", \"departureTime\": \"2020-11-02T03:30:00.000+00:00\", \"arrivalTime\": \"2020-11-02T04:30:00.000+00:00\" }]3. reserve seatsEndpoint url:- http://localhost:8080/flight/reserveSeats/{userId}/{flightNumber}/{source}/{destination}/{date}/{seats}Request Type-GET methodExample:Request:- http://localhost:8080/flight/reserveSeats/1/101/jaipur/bangalore/2020-11-02/13Response:-{ \"id\": 7, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 13}Request:- http://localhost:8080/flight/reserveSeats/1/101/jaipur/bangalore/2020-11-02/65Response:- only 32 tickets are available4. view reservationEndpoint url:- http://localhost:8080/user/viewReservation/{userId}Request Type-GET methodRequest:-http://localhost:8080/user/viewReservation/1Response:- [ { \"id\": 1, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 2 }, { \"id\": 2, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-09\", \"reserveSeats\": 2 }, { \"id\": 3, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 1 }, { \"id\": 4, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 2 }, { \"id\": 5, \"flightnumer\": 102, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-03\", \"reserveSeats\": 15 }, { \"id\": 6, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 5 }, { \"id\": 7, \"flightnumer\": 101, \"fromAirport\": \"jaipur\", \"toAirport\": \"bangalore\", \"date\": \"2020-11-02\", \"reserveSeats\": 13 }]" }, { "title": "Roadmaps For Os Dbms And Oops", "url": "/posts/Roadmaps-for-OS-DBMS-and-Oops/", "categories": "", "tags": "", "date": "2020-01-26 00:00:00 +0530", "snippet": "OOPS RoadMap- credit @loveBabbarDBMS RoadMap- credit @loveBabbarOS RoadMap- credit @loveBabbar" }, { "title": "Meltdown Attack", "url": "/posts/Meltdown-Attack/", "categories": "", "tags": "", "date": "2020-01-05 00:00:00 +0530", "snippet": "Github:- https://github.com/mukeshpilaniya/meltdown International Institute of Information Technology(IIIT), Bangalore Meltdown Attack Mentor Prof.Thangaraju B Professor,IIIT-Bangalore Mukesh Kumar Pilaniya Shreyansh Jain M.Tech 1 st Year M.Tech 1 st Year MT2019068 MT2019106 Contents Introduction Background 2.1 Cache Side Channel and Attacks 2.1.1 FLUSH+RELOAD attack 2.2 Out-Of-Order Execution 2.3 Address Space Randomization Meltdown and its Components 3.1 Transient Instruction 3.2 Attack Description Evaluation 4.1 Environment Setting 4.2 Code Compilation 4.3 Reading from Cache versus Main Memory 4.4 Using Cache as Side-Channel 4.5 Prepration for Meltdown Attack 4.6 Exception Handling 4.7 Out-of-Order Execution 4.8 Meltdown Attack Prevention of Meltdown Attack - KAISER Patch ConclusionAbstractApplication security relies on the memory mapping in the system as well as isolationif memory unit and memory management unit is responsible for that like kernel addresssystem space that are marked as not accessible from user space and are marked aspriviliged. In this paper, we present Meltdown, Meltdown exploit vulnerabilities ofout-of-order execution which allows a user program to read data stored inside thekernel-level memory that are marked as not accessible from user-level program.Such, accessing of data is not allowed by the hardware level protection mechanismimplemented in Central Processing Unit(CPU), but the vulnerability exists in thedesign of these CPU and mostly intel CPU are affected by meltdown. Meltdownbreaks all the security guarantees of a system which is not patched by KASLR.1 IntroductionA operating system provide security to each application using memory isolation technique.Operating system provide guarantee that one application or program can not access other application data without permission of operating system(kernel).Kernel level permission bit is set by hardware level mechanism known as supervisor bit. Supervisor bit provide isolation between kernel address space and user address space. So, the aim is that this bit could only be set when entering into kernel space and it’s cleared when switching to user process(mode) space. This hardware feature allows OS to map kernel address space to address space of other user process and it is an very efficient address transitions scehme.(1)(9)In this paper, we present Meltdown, the attack itself is quite complex,therefore we break it down into quite small steps so that each step is easy to understand.(1)(9) Meltdown does not exploit any kind of software vulnerability i.e it does not use or break internal software system but it is a hardware attack and it works on all the major intel system. The major cause of meltdown attack isout-of-order execution.(1)(9)Out-of-order execution increases CPU efficiency and allows CPU to execute instruction faster and, in a second half of the paper we have describe it in short. Through Out-of-Order execution we exploit cache side channel to catch data store in L3 cache. However, out-of-order attacks cache side channel and the result allows an attacker to dump whole kernel memory by reading cache memory in an out-of-order execution manner.(1)(9)Outline In this section we will describe about Cache Side channel and attacks Out-Of-Order Execution Address Spaces Randomization Meltdown and Its Components Evluation Conclusion2 BackgroundIn this section we describe cache side channel, out-of-order execution and address space randomization.2.1 Cache Side Channel and AttacksCache based attack on the processor were happening for a number of years, meltdown and spectre are famous known attacks of Cache side channel. Cache side channel attacks are enabled using the micro architecture design of the processor. They are part of hardware design and thus they are very difficult to defeat.(9)(10) In order to speed up memory access and address translation CPU contains the small memory known as cache memory that store frequently used data. Every instruction and every piece of data that require main memory. The CPU retrieves the instruction and data from main memory execute that instruction and store result back in main memory. So, to improve per-formance of accessing main memory a hardware level access is made to various level of cache memory. If the require instruction or data already in cache memory CPU retrieved that data from cache execute it and save back to cache, with the help of various write back policy cache data is written back to main memory eg: - write back and write through.(1)(4)(9)Here, the main point is cache memory is used for storing frequently access data. The attacker can not directly read data stored in cache memory but this does not mean that there is not information leakage, the cache is much smaller than main memory and nearest to the CPU, so data retrieving from cache memory is much faster than accessing data from main memory. Cache side channel exploit this timing difference for retrieving data. Differ-ent cache technique has been proposed in the past including Evict+Time, Prime+Probe and Flush+Reload.(2) The next piece of background information required to understand the CPU cache topology of modern processors. Figure [1] shows a generic topology that is common to most of modern CPU’s. Modern CPU’s generally contain multiple levels of cache memory. In this figure we assume that CPU is dual core and each core contains its own L1 and L2 cache memory and L3 cache is shared in between core0 and core1. We exploiting cache side channel attack in L3 cache only because that is practical to exploit and for side channel attack, we are usingFlush+Reload technique because it’s works on a single cache line granularity.(1)(4)(9)All the technique works this way: manipulate cache to known state, wait for victim activityand examine what has changed. Program virtual address map to physical address with thehelp of page table. L1 cache is nearest to the CPU and split between a data and an instruc-tion cache. If the data not found in L1 cache than load instruction passed to the next Cachehierarchy. This is the point where the page table come into play. Page table are used to Figure 1: Cache Architecturetranslate virtual address into a physical address, once’s we have physical address CPU canquery into L2 cache and if data is not found in L2 cache then Load instruction is passed toL3 cache. L3 is inclusive shared cache between core0 and core1.(3)(9)2.1.1 FLUSH+RELOAD attackUsing Flush+Reload an attacker can exploit last-level shared inclusive cache i.e Level3 cache,an attacker frequently flush a targeted memory location using theclflush instruction and thereby measuring the time it takes to reload the data, now the attacker can know whether data was loaded into the cache memory by another application or any current process in the meantime.(1)(9)2.2 Out-Of-Order ExecutionOut-Of-Order execution allows processor to execute the instructions one after the other, the processor uses the resources not to its full extent which makes CPU performance ineffi-cient.Thus, to improve the efficiency of CPU, there are two methods,first by executing various sub-steps of sequential instructions at the same time(simultaneously) or secondly maybe by executing instructions simultaneously depending on the resources availability. Further im-provement within the CPU can be achieved byOut-of-Order Execution. Out-of-orderinstruction execution are usually achieved by executing the instruction in an various different form.(4)(9)Out-of-order execution is a method or approach that is utilized in high performance micro-processors. Out-Of-Order efficiently uses instruction cycles (Instruction Cycles is a process by which a computer system pulls program instruction from the memory which can invoke pre-fetching or pre-processing, also determines what action the instruction requires or what resources it needs and carries out those actions.) and reduces costly delay due to resourceunavailability. A processor will execute the instruction order of availability of knowledge or operands or resources rather than original order of the instructions in the program. Throughthis, the CPU will avoid being idle or free while data is retrieved for the next instruction in advance for a program.(4)(9) Out-of-Order Execution can be regarded asA Room guarded by a Security Officer.The attacker wants to enter the room to get some secret value but the Security Guard have 2 options either it can allow the attacker to access the data depending on the permissions orit can deny the attacker to access the room’s data.(4)(9) Figure 2: Out-Of-Order ExecutionIn figure 2 the line 3 causes an interrupt because user(attacker) wants to access the kerneldata, this line leads CPU to do two things The CPU raises an exception since user level program want to access kernel level data, this causes program or application to either crash if the program doesn’t have exception handling mechanism. Mean-while when CPU is busy in permission check the CPU doesn’t want the other com-putational parts to be idle since this may degrade the performance or efficiency so the CPU execute the adjacent instructions depending on the availability of data operands.Now the user is either allowed or denied to access the data, but in both cases due to Out-of-Order Executionthe adjacent instructions are executed. If the permission is granted then the adjacent instructions are successfully executed but if the permission is denied the program or application may abruptly end(or may show appropriate message depending on the Exception Handling Mechanism) but in both cases the value from the kernel is fetched by the CPU and stored in a temporary register inCache Memory. The Cache Memory is not flushed in either case of access permission check, that means the data is still availablesomewhere in the Cache. So from outside or user point of view the attacker has not accessed the data but from inside it can still access the data through Cache Memory via Timing Difference.(1)(4)(9)We will show in the Evaluation(Section 5) the proof of Out-of-Order Execution that how the attacker can access the secret data.2.3 Address Space RandomizationCPU’s support two kind of address spaces so that processes are isolated from each other. Virtual Address Spacescan be defined as virtual addresses that are translated to phys-ical(logical) addresses through page translation tables. Virtual address space is divided into a group of pages that will be mapped to the corresponding logical or physical memory through a multi-level page translation table. The page translation tables are used to define the specific mapping virtual to physical address and also protection bit(like dirty bit etc)properties that are used to force privilege checks, like read access, write access, executable or not and user-accessible or not. The currently used translation table is stored in a special CPU register. On each context switch(change of process states), the OS updates this register with corresponding process translation table address so as to implement per-process virtualaddress spaces.Thus, each process can only refer to data that belongs to its own virtual address space. Every virtual address space is divided into two categories which are User and Kernelparts so that each process gets a user and kernel address space. The currently running application uses the user address space, while the kernel address space would only be accessed if CPU is running(active) and also in privileged mode(mode bit set to 1). This is done by the operating system which disable the user-accessible property of the current orspecific translation tables. The kernel address space does not only have memory mapped for the kernel’s own use, but it must also perform operations on the user pages. As a result of this, the whole physical memory is mapped with the kernel.(1)(4)(9)3 Meltdown and its ComponentsMeltdown Attack uses flaw in most of the modern processors.These flaws exists in the CPU’s itself i.e it can be regrded as a Hardware Defect rather than a software bug, it allows a user-level program to read data stored inside the kernel memory. We cannot access kernel space due to the hardware protection mechanism, but a defect exists in the design of these CPU’s which allows to defeat the hardware protection and thus carry out these types of attacks.Because the defect exists within the hardware,it is very difficult to fundamentally fix the problem, unless we change the CPU’s in our computers.(1)(4)(9)3.1 Transient InstructionBefore doing an in-depth analysis of how meltdown takes place, first we need to understand what is Transient Instruction.Any Instruction that executes Out-of-order in the program and has measurable side effects is known as Transient Instruction.Transient instructions occur all the time, because the CPU runs ahead of the current in-struction all the time to minimize the experienced latency and, thereby, to maximize the performance or efficiency.These instructions introduce an exploitable side channel if their operation depend on a secret value. We specialise in addresses that are mapped within the attacker’s process, i.e., the user-accessible user space addresses as well as the user-inaccessible which may kernel space addresses or other user’s address space.The attacks targeting code that is executed within the context (i.e., address space) of other user processess are also possible, but out of context in this work, because the physical memory (including the memory of other user processes) they are read through the kernel space.(1)(4)(9)3.2 Attack DescriptionMeltdown attack can be divided into 3 steps: To know Secret Kernel Address SpaceThe content of an attacker chosen memorylocation which is stored in kernel space address and which can not be accessed by the attacker, is loaded into a register. Out-of-Order Instruction ExecutionA transient instruction which is an out-of-order instruction accesses the cache line supported by the register. Using Cache as Side Channel to read the secret dataThe attacker uses Flush+Reload technique (Timing Difference Attack) to work out the cache line accessed in the previous step and thus the secret stored at the specified memory location.Since these is only applicable for single memory location if the attacker uses these technique for other locations then it can get the secret from other locations in kernel space as wellwhich may lead to unavoidable consequences.(1)(2)(4)(9)4 EvaluationIn this section we describe each step that need to done for performing meltdown attack.4.1 Environment SettingFor setting up our lab environment we are using 64-bit ubuntu 16.04 LTS in oracle virtual box 6.0, setting related to hardware device is specified in given 3. Figure 3: Environment Setting4.2 Code CompilationWhile compiling source code we have to add -march=native flag. while compiling the pro-gram -march=native flag tells the compiler to produce specific code for the local machine.For, example to compile a myprogram.c we are using the following command :gcc-march=native -o myprogram myprogram.c4.3 Reading from Cache versus Main MemoryCache memory is nearest to CPU so, first CPU check data in cache, if data is present in cache than it will fetch directly from it and if data is not present than it will fetch from main memory. Fetching data from cache is much faster than fetching data from main memory.gcc -march=native -o CacheTime CacheTime.cIn the Figure 4 at line number 19, first we have initialized an array of size 10*PAZESIZE.For finding PAGESIZE run the following command in terminal “getconf PAGESIZE” and put your own PAGESIZE in line 8. After that we flush the array address to make sure that array indexes are not cached and in the next phase, we are accessing index 4 and 7 as shown in line number 25 and 26 so that index 4 and 7 is cached by cache. From line number 29 to 35 we are accessing the array index and measuring the timing using rdtscp time stamp. Figure 4: Program Illustrating the Timing Difference of Probing ArrayFigure 5 illustrate the timing difference where accessing the array index 3 and 7 is much faster than others. Figure 5: Access Timing of Probing Array4.4 Using Cache as Side-ChannelThe objective of this section is extracting a secret value used by the victim function. We are assuming that victim(); function at line 53 uses a secret value define in line 14, as index to load values from an array and the secret value cannot be accessed from the outside. Our objective is to use side channel to get this secret value. The technique that we are using forretrieving secret value is Flush(line 16)+Reload(line27) Functions.As Shown in Figure 6 at line 14, first we set one-byte secretValue variable equal to 105.Since for a one-byte secret value there are 256 possibilities so in line 12 we declare array of size 256PAGESIZE. We multiply by PAGESIZE because caching is done at a block level, not at a byte level so, if one byte is cached by cpu than adjacent byte will also cached. Since the first array[0PAGESIZE] may also cached by some cache block as a default behavior of cache. Therefore, to make sure array[0PAGESIZE] will not cached we are accessing array[iPAGESIZE+DELTA], where DELTA is a constant define in line number 10. Figure 6: Program showing Cache is used as a Side ChannelFirst Flush the entire array using flushSideChannel(); from the cache memory to make sure that array is not cached. After that we invoke the victim(); function, which access of the array element based on the value of secret, that array index value is cached by the cache memory. And the final step is calling the reloadSideChannel(); function which reload the entire array and measure the time it takes to reload each element. So, if the array index is previously cached than it requires less CPU cycle. The output of the program illustrates in Figure 7.The output of the program shown in fig 6 below: Figure 7: Reading of Secret Value from Cache4.5 Prepration for Meltdown AttackFor preparing meltdown attack we have to placed secret value in kernel space and we show that how a user-level program can access that data without going into kernel space. To store the Secret value in kernel space we are using kernel Module approach and the code is listed in 8. Figure 8: Program illustrating Meltdown AttackFor executing the meltdown attack first, we need to know address of secret value so, the kernel module saves the address of secret value in kernel buffer at line 41. which we will get it using ‘dmseg‘ command as shown in Figure 9. The next thing is this secret value need to be cached so to achieve this we are creating a file /proc/secretdata at line number 46. Which provide a link to communicate a user level program to kernel module. Therefore, when a user-level program read /proc/secretdata file then it will invoke readproc() function at line 23. The readproc() function will load the secret value (line 25) which is cached by CPU. readproc() function will not return secret value so it does not leak secret value. Compile the kernel module make Install the kernel module sudo insmod MeltdownKernel.ko Print secret value address dmesg Figure 9: dmesg command4.6 Exception HandlingWhen user program tries to access kernel memory in Figure 10 at line 23 than memory access violation is triggered and segmentation fault is generated. To avoid segmentation fault, we are using SIGSEGV signal because c does not provide try/catch techniques like java. So to implement try/catch in c we are using sigsetjmp() at line 21 and siglongjmp at line 10. Figure 10: Exception HandlingThe execution of this program is quite complex but let’s understand it line by line. First,we register a SIGSEGV signal handler in line 19 which will invoke catchsegv function (line7). once’s the signal handler complete processing it let the program to continue its execution so for that we have to define a checkpoint that we are achieve by sigsetjmp(buffer,1) at line 21. sigsetjmp save the stack context in buffer that it latter used by siglongjmp (line 10).siglongjmp rollback the stack context in buffer and return the second argument which is 1 so the program execution is start form else part (line 29), output is illustrate in 11. Figure 11: Output of Exception Handling Program4.7 Out-of-Order ExecutionMeltdown is a race condition vulnerability, which involves racing between out-of-order exe-cution and access block so, for exploiting meltdown successfully we must have to win racecondition. To win race condition we have to keep CPU execution busy somehow and forthat we are using assembly level code. Figure 12: Out-of-Order ExecutionThe code in Figure 12 is simply a loop over 400 times (line 63). In the next line it adds anumber 0X141 (321 in decimal) to the eax register to keep rax register busy so that we canwin race condition.4.8 Meltdown AttackTo make attack more practical and improve efficiency of attack we create a score array of size 256. The reason of creating an array of size 256 is that for one byte there is 256 possibilities.Therefore, one element for each possible secret value and we run attack multiple times asshown in Figure 13 at line 92. This step is combination of all step that are describe above,after running multiple times the highest value of score array is our answer. The output ofthis step is illustrated in Figure 14. Figure 13: Reading Secret Value from Kernel Figure 14: Output- Program Reading Secret Value from Kernel`The code in MeltdownAttack can only steals a one byte secret from the kernel.`5 Prevention of Meltdown Attack - KAISER PatchThe exploitation in the memory attacks usually requires correct knowledge of addresses ofspecific data. So in order to carry out these attacks,Address Space Layout Random-ization (ASLR)has been introduced. To protect kernel, KASLR randomizes the offsetswhich means the starting address from where the system is loaded and is changed every timethe system is booted , making attacks harder as the attacker now require to guess the situa-tion of kernel data structures.(1)(4)(9) But, with side channel, the attacker has to preciselydetermine the kernel address. A combination of a software bug and the knowledge of thephysical addresses can lead to privileged code execution.(1)(4)(9)To Prevent Meltdown KAISER technique can be used more accurately or we can say that itis a counter measure to Meltdown Attack. KAISER hide the kernel space from user spaceusing randomization technique. KAISER allow the kernel to randomize the kernel locationat boot time. The Output of same program after applying KAISER patch is illustrated in Figure 15. Figure 15: KAISER PATCH6 ConclusionIn this paper we presented Meltdown, a vulnerability or attack to the software system whichcan read kernel data or secret data from an underprivileged user-level program, since it doesnot depend on any software vulnerability as well as it is independent of the type of OperatingSystem.To prevent Meltdown KAISER can be used more accurately we can say that it is a counter-measure to Meltdown Attack, it is a kernel modification to not have the kernel mapped inthe user space.This modification to protect side channel attacks breaking KASLR(KernelAddress Space Layout Randomization) but it also prevents Meltdown.References[1] ZhengZmy(2019)Meltdown: Reading Kernel Memory from User Space https://blog.csdn.net/zheng_zmy/article/details/[2] Wenliang Du, Syracuse University(2018)Meltdown Attack Lab http://www.cis.syr.edu/~wedu/seed/Labs_16.04/System/Meltdown_Attack[3] Areej(2020) -Difference between l1 l2 and l3 cache memory[4] Moritz Lipp,Michael Schwarz,Daniel Gruss Metldown paper https://arxiv.org/pdf/1801.01207.pdf[5] Jacek Galowicz Metldown paper https://blog.cyberus-technology.de/posts/2018-01-03-meltdown.html[6] Jann Horn, Project Zero Reading privileged memory with a side channel https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html[7] Jake Edge Kernel Address Space Layout Randomization(KASLR) https://lwn.net/Articles/569635/[8] Daniel Gruss,Clementine Maurice, Klaus Wagner, and Stefan MangardFlush+Flush:A Fast and Stealthy Cache Attack https://gruss.cc/files/flushflush.pdf[9] Jann Horn, Project Zero Reading privileged memory with a side channel https://cryptome.org/2018/01/spectre-meltdown.pdf[10] Yinqian Zhang Cache Side Channels: State of the Art and Research Oppor tunities http://web.cse.ohio-state.edu/~zhang.834/slides/tutorial17.pdf" }, { "title": "Oaes Design Pattern", "url": "/posts/OAES-Design-Pattern/", "categories": "", "tags": "", "date": "2018-12-10 00:00:00 +0530", "snippet": "OAES Design Pattern ActivityDesign Problem:- Let's suppose that for giving an exam a student has to go into the exam center and the exam starts at a specific time that is prior known to the student. Exam server also has a list of registered Students(Subscribers) and ExamServer sends question papers to register students screen automatically when the exam starts. So for all the students, server will not fetch question paper from database all the time, it will fetch only for one student and for rest of them it will create a clone of a question paper, so it will follow Prototype design Pattern and for sending Question Paper to registered student it will follow Observer design pattern.Design Pattern:- observer design pattern while sending question Paper to registered Students, ProtoType design pattern while creating a clone of question Paper.Overview:- notifyResteredStudent()- method sent Question Paper to all registered Student who are appearing for exam Cloneable- Inbuilt java interface methi\\od for cloning question paper" } ]
